{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0179871a-d3c7-4d70-be2b-b2ea08608e98",
   "metadata": {},
   "source": "## Step 2: Training a simple model"
  },
  {
   "cell_type": "code",
   "id": "4188dd8a-b293-44e2-9da1-c6bfbe71ff67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "# install pathology-whole-slide-data if needed\n",
    "!pip3 install git+https://github.com/DIAGNijmegen/pathology-whole-slide-data@main"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4276a6c4-fdf6-4e30-ba95-ea101c4c52f1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "# install detectron2 if needed\n",
    "!pip3 install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.9/index.html"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d90089db-4fff-4251-8ee0-a8df720937ab",
   "metadata": {},
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from wholeslidedata.interoperability.detectron2.iterator import WholeSlideDetectron2Iterator\n",
    "from wholeslidedata.interoperability.detectron2.trainer import WholeSlideDectectron2Trainer\n",
    "from wholeslidedata.interoperability.detectron2.predictor import Detectron2DetectionPredictor\n",
    "from wholeslidedata.iterators import create_batch_iterator\n",
    "from wholeslidedata.visualization.plotting import plot_boxes\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.modeling import build_model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "428f7c17-9756-4142-8fb7-7d6ff53fc43d",
   "metadata": {},
   "source": "Setting up the training configuration and parameters (can also be defined in a separate yaml file)."
  },
  {
   "cell_type": "code",
   "id": "183114ea-d20b-4e6f-b443-1613114991d1",
   "metadata": {},
   "source": [
    "user_config = {\n",
    "    'wholeslidedata': {\n",
    "        'default': {\n",
    "            'yaml_source': \"./configs/training_sample.yml\",\n",
    "#             \"seed\": 42,\n",
    "            \"image_backend\": \"asap\",\n",
    "            'labels': {\n",
    "                \"ROI\": 0,\n",
    "                \"lymphocytes\": 1\n",
    "            },\n",
    "        \n",
    "            \n",
    "            'batch_shape': {\n",
    "                'batch_size': 10,\n",
    "                'spacing': 0.5,\n",
    "                'shape': [128,128,3],\n",
    "                'y_shape': [1000, 6],\n",
    "            },\n",
    "            \n",
    "            \n",
    "            \n",
    "            \"annotation_parser\": {\n",
    "                \"sample_label_names\": ['roi'],\n",
    "            },\n",
    "            \n",
    "            'point_sampler_name': \"RandomPointSampler\",\n",
    "            'point_sampler': {\n",
    "                \"buffer\": {'spacing': \"${batch_shape.spacing}\", 'value': -64},\n",
    "            },\n",
    "            \n",
    "            'patch_label_sampler_name': 'DetectionPatchLabelSampler',\n",
    "            'patch_label_sampler': {\n",
    "                \"max_number_objects\": 1000,\n",
    "                \"detection_labels\": ['lymphocytes'],\n",
    "                    \n",
    "            },\n",
    "            \n",
    "        }\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "31603a59-991b-4e0d-aced-058783ff6bba",
   "metadata": {},
   "source": "Creating the batch generator."
  },
  {
   "cell_type": "code",
   "id": "cb240196-0e67-4afd-a2ca-29fab92df1dd",
   "metadata": {},
   "source": [
    "training_batch_generator = create_batch_iterator(\n",
    "    user_config=user_config,\n",
    "#     user_config=r'./configs/training_config.yml',\n",
    "    mode='training',\n",
    "    cpus=1,\n",
    "    iterator_class=WholeSlideDetectron2Iterator,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2d0cc18a-2294-4e61-9fd3-faac4cd0eb5c",
   "metadata": {},
   "source": "Visualizing a sample batch."
  },
  {
   "cell_type": "code",
   "id": "a4547b5d-0aa5-425f-ac02-c551799df90f",
   "metadata": {},
   "source": [
    "batch_dicts = next(training_batch_generator)\n",
    "\n",
    "for _ in range(20):\n",
    "    batch_dicts = next(training_batch_generator)\n",
    "    fig, ax = plt.subplots(1,8, figsize=(20,10))\n",
    "    for i in range(8):\n",
    "        patch = batch_dicts[i]['image'].cpu().detach().numpy().transpose(1,2,0).astype('uint8')\n",
    "        _boxes =  batch_dicts[i]['instances'].gt_boxes.tensor.cpu().detach().numpy()\n",
    "        boxes = np.ones((len(_boxes), 6))\n",
    "        boxes[..., :4] = _boxes\n",
    "        max_width, max_height = batch_dicts[i]['instances'].image_size\n",
    "        ax[i].imshow(patch)\n",
    "        plot_boxes(boxes, max_width=max_width, max_height=max_height, axes=ax[i])\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e20fe383-a488-4a36-baed-dd7bfe71594a",
   "metadata": {},
   "source": "Creating the output folder for saving the model and results."
  },
  {
   "cell_type": "code",
   "id": "fb23526f-0964-4222-8728-1b0be9a36c08",
   "metadata": {},
   "source": [
    "output_folder = Path('./outputs')\n",
    "if not(os.path.isdir(output_folder)): os.mkdir (output_folder) \n",
    "cpus = 4"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "afd02ed9-9554-4ff6-b572-7cd8cdabb2cf",
   "metadata": {},
   "source": "# Train the model"
  },
  {
   "cell_type": "code",
   "id": "7cb884b8-72d1-4619-a53a-63aa81064273",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "cfg = get_cfg()\n",
    "# using faster rcnn architecture\n",
    "cfg.merge_from_file(\n",
    "    model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
    ")\n",
    "\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"detection_dataset2\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 1\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[16, 24, 32]]\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 10\n",
    "cfg.SOLVER.BASE_LR = 0.001  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 2000  # 2000 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = (10, 100, 250)\n",
    "cfg.SOLVER.WARMUP_ITERS = 0\n",
    "cfg.SOLVER.GAMMA = 0.5\n",
    "\n",
    "cfg.OUTPUT_DIR = str(output_folder)\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "model = build_model(cfg)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Parameter Count:\\n\" + str(pytorch_total_params))\n",
    "\n",
    "trainer = WholeSlideDectectron2Trainer(cfg, user_config=user_config, cpus=cpus)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c9af434d-a60d-45b9-b230-5384126283e3",
   "metadata": {},
   "source": "Evaluation."
  },
  {
   "cell_type": "code",
   "id": "636aa5d3-e3c5-4f0f-b9ef-75f8c96c17c4",
   "metadata": {},
   "source": [
    "cfg = get_cfg()\n",
    "\n",
    "cfg.merge_from_file(\n",
    "    model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
    ")\n",
    "\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"detection_dataset2\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 1\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256  \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[16, 24, 32]]\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 10\n",
    "cfg.SOLVER.BASE_LR = 0.001  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 2000  # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "cfg.SOLVER.WARMUP_ITERS = 0\n",
    "cfg.SOLVER.GAMMA = 0.5\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.1\n",
    "\n",
    "cfg.OUTPUT_DIR = str(output_folder)\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(output_folder, \"model_final.pth\")\n",
    "\n",
    "model = build_model(cfg)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Parameter Count:\\n\" + str(pytorch_total_params))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a752e325-2376-44ea-b432-4ee983dca331",
   "metadata": {},
   "source": [
    "predictor = Detectron2DetectionPredictor(cfg)\n",
    "with create_batch_iterator(\n",
    "    user_config=user_config,\n",
    "    mode='training',\n",
    "    cpus=4,\n",
    ") as training_batch_generator:\n",
    "    for _ in range(10):\n",
    "        fig, ax = plt.subplots(1,10, figsize=(20,10))\n",
    "        batch_x, batch_y, info = next(training_batch_generator)\n",
    "        predicted_batch = predictor.predict_on_batch(batch_x)\n",
    "        for i in range(10):\n",
    "            patch = batch_x[i]\n",
    "            boxes =  predicted_batch[i]['boxes']\n",
    "            confidences = predicted_batch[i]['confidences']\n",
    "            filtered_boxes = []\n",
    "            for box, confidence in zip(boxes, confidences):\n",
    "                if confidence > 0.3:\n",
    "                    filtered_boxes.append(box)\n",
    "            ax[i].imshow(patch)\n",
    "            plot_boxes(filtered_boxes, max_width=64, max_height=64, axes=ax[i])\n",
    "        plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
