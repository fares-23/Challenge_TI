{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf5abbf4-91c4-495d-a0e1-5791544d3ba4",
   "metadata": {},
   "source": [
    "# Step 3: Creating the model inference script\n",
    "To submit your algorithm to the challenge, you need to create an inference docker container. "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# install pathology-whole-slide-data if needed\n",
    "!pip3 install git+https://github.com/DIAGNijmegen/pathology-whole-slide-data@main"
   ],
   "id": "92f36f61-dbac-49a0-921f-c56055fc0698",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6242dded-dd77-42fa-8933-3a6201aa88cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# install detectron2 if needed\n",
    "!pip3 install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.9/index.html"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bf8859c4-c9a9-4371-a84e-9e3b8a9a7e43",
   "metadata": {
    "tags": []
   },
   "source": [
    "!pip3 install creationism"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a84728b1-6166-400b-8ff7-312fc87145bb",
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import creationism\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "from wholeslidedata.interoperability.asap.annotationwriter import write_point_set\n",
    "from wholeslidedata.image.wholeslideimage import WholeSlideImage\n",
    "from wholeslidedata.iterators import create_patch_iterator, PatchConfiguration\n",
    "from wholeslidedata.annotation.labels import Label\n",
    "\n",
    "from utils.wsdetectron2 import Detectron2DetectionPredictor\n",
    "from utils.structures import Point"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "49fcf108-70f5-4339-be0e-358e07909d3a",
   "metadata": {},
   "source": "Setting up the paths."
  },
  {
   "cell_type": "code",
   "id": "00f91aee-5195-4366-9c2d-73542eb65e7a",
   "metadata": {},
   "source": [
    "image_path = r'./data/images/DI_S02_P000001.tif'\n",
    "mask_path = r'./data/ROI_masks_025/DI_S02_P000001_mask.tif'\n",
    "output_path = r\"./outputs/results\"\n",
    "if not(os.path.isdir(output_path)): os.mkdir (output_path) \n",
    "json_filename = \"detected-lymphocytes.json\"\n",
    "\n",
    "print(f\"Pytorch GPU available: {torch.cuda.is_available()}\")\n",
    "print(image_path, mask_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1fd1031a-b590-4917-86e1-768a31a71147",
   "metadata": {},
   "source": "Defining patch configuration for each image."
  },
  {
   "cell_type": "code",
   "id": "3f99bab4-b6e2-45fc-9b5d-1ff12437b136",
   "metadata": {},
   "source": [
    "patch_shape=(128,128,3)\n",
    "spacings=(0.5,)\n",
    "overlap=(0,0)\n",
    "offset=(0,0)\n",
    "center=False\n",
    "\n",
    "patch_configuration = PatchConfiguration(patch_shape=patch_shape,\n",
    "                                         spacings=spacings,\n",
    "                                         overlap=overlap,\n",
    "                                         offset=offset,\n",
    "                                         center=center)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a86930aa-5184-46c1-b9c0-13e723d56bdb",
   "metadata": {},
   "source": "Loading the saved model."
  },
  {
   "cell_type": "code",
   "id": "4122d05f-8153-4dde-9abf-362b8311217b",
   "metadata": {},
   "source": [
    "model = Detectron2DetectionPredictor(\n",
    "    output_dir=output_path,\n",
    "    threshold= 0.1,\n",
    "    nms_threshold=0.3,\n",
    "    weight_root = \"./outputs/model_final.pth\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d4167cee-bdb9-4f8a-9103-e97c9ce31ac0",
   "metadata": {},
   "source": "Creating a patch iterator using the roi mask and sliding windows."
  },
  {
   "cell_type": "code",
   "id": "b6b3e546-321f-4797-8649-cceeed9a5c28",
   "metadata": {},
   "source": [
    "iterator = create_patch_iterator(image_path=image_path,\n",
    "                               mask_path=mask_path,\n",
    "                               patch_configuration=patch_configuration,\n",
    "                               cpus=4,\n",
    "                               backend='asap')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b9487fdd-67d7-4d1a-aff0-fbff7bb63b2e",
   "metadata": {},
   "source": "Some useful functions."
  },
  {
   "cell_type": "code",
   "id": "9eb0e923-9a7d-4cca-924f-f6383a9cddcd",
   "metadata": {},
   "source": [
    "def px_to_mm(px: int, spacing: float):\n",
    "    return px * spacing / 1000\n",
    "\n",
    "def to_wsd(points):\n",
    "    \"\"\"Convert list of coordinates into WSD points\"\"\"\n",
    "    new_points = []\n",
    "    for i, point in enumerate(points):\n",
    "        p = Point(\n",
    "            index=i,\n",
    "            label=Label(\"lymphocyte\", 1, color=\"blue\"),\n",
    "            coordinates=[point],\n",
    "        )\n",
    "        new_points.append(p)\n",
    "    return new_points\n",
    "\n",
    "def write_json_file(*, location, content):\n",
    "    # Writes a json file\n",
    "    with open(location, 'w') as f:\n",
    "        f.write(json.dumps(content, indent=4))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e6511c62-3c21-4f7d-8dc7-2246459c8ec7",
   "metadata": {},
   "source": "Run inference on an image with loaded model."
  },
  {
   "cell_type": "code",
   "id": "c9f7e6e3-5bb5-4dd7-a9d4-7097700691de",
   "metadata": {
    "tags": []
   },
   "source": [
    "def inference(iterator, predictor, spacing, image_path, output_path, json_filename):\n",
    "    print(\"predicting...\")\n",
    "    output_dict = {\n",
    "        \"name\": \"lymphocytes\",\n",
    "        \"type\": \"Multiple points\",\n",
    "        \"version\": {\"major\": 1, \"minor\": 0},\n",
    "        \"points\": [],\n",
    "    }\n",
    "\n",
    "    annotations = []\n",
    "    counter = 0\n",
    "    \n",
    "    spacing_min = 0.25\n",
    "    ratio = spacing/spacing_min\n",
    "    with WholeSlideImage(image_path) as wsi:\n",
    "        spacing = wsi.get_real_spacing(spacing_min)\n",
    "\n",
    "\n",
    "    for x_batch, y_batch, info in tqdm(iterator):\n",
    "        x_batch = x_batch.squeeze(0)\n",
    "        y_batch = y_batch.squeeze(0)\n",
    "\n",
    "        predictions = predictor.predict_on_batch(x_batch)\n",
    "        for idx, prediction in enumerate(predictions):\n",
    "\n",
    "            c = info['x']\n",
    "            r = info['y']\n",
    "\n",
    "            for detections in prediction:\n",
    "                x, y, label, confidence = detections.values()\n",
    "\n",
    "                if x == 128 or y == 128:\n",
    "                    continue\n",
    "\n",
    "                if y_batch[idx][y][x] == 0:\n",
    "                    continue\n",
    "                \n",
    "                x = x*ratio + c # x is in spacing= 0.5 but c is in spacing = 0.25\n",
    "                y= y*ratio + r\n",
    "                prediction_record = {\n",
    "                    \"name\" : \"Point \"+str(counter),\n",
    "                    \"point\": [\n",
    "                        px_to_mm(x, spacing),\n",
    "                        px_to_mm(y, spacing),\n",
    "                        0.24199951445730394,\n",
    "                    ],\n",
    "                    \"probability\": confidence,\n",
    "                }\n",
    "                output_dict[\"points\"].append(prediction_record)\n",
    "                annotations.append((x, y))\n",
    "                counter += 1\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Predicted {len(annotations)} points\")\n",
    "    print(\"saving predictions...\")\n",
    "\n",
    "    # saving xml file\n",
    "    annotations_wsd = to_wsd(annotations)\n",
    "    xml_filename = 'points_results.xml'\n",
    "    output_path_xml = os.path.join(output_path,xml_filename)\n",
    "    write_point_set(\n",
    "        annotations_wsd,\n",
    "        output_path_xml,\n",
    "        label_color=\"blue\",\n",
    "    )\n",
    "\n",
    "        \n",
    "    # saving json file\n",
    "    output_path_json = os.path.join(output_path, json_filename)\n",
    "    write_json_file(\n",
    "        location=output_path_json,\n",
    "        content=output_dict\n",
    "    )\n",
    "\n",
    "    print(\"finished!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7bf43390-c419-4b8a-9f5a-104cb8040592",
   "metadata": {},
   "source": [
    "inference(\n",
    "    iterator=iterator,\n",
    "    predictor=model,\n",
    "    spacing = spacings[0],\n",
    "    image_path=image_path,\n",
    "    output_path=output_path,\n",
    "    json_filename=json_filename\n",
    ")\n",
    "\n",
    "iterator.stop()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "71124d71-9322-4cd8-b608-d80c1ea90e96",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
